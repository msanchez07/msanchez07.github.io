

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Descenso de Gradiente &#8212; Programación de inteligencia artificial</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=c5ced968eda925caa686" rel="stylesheet" />
<link href="../../../_static/styles/bootstrap.css?digest=c5ced968eda925caa686" rel="stylesheet" />
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=c5ced968eda925caa686" rel="stylesheet" />

  
  <link href="../../../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=c5ced968eda925caa686" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css" />
    <link rel="stylesheet" href="../../../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/css/notebook.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/css/notebook.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/css/notebook.css" />
    <link rel="stylesheet" type="text/css" href="../../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/bootstrap.js?digest=c5ced968eda925caa686" />
<link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=c5ced968eda925caa686" />
  <script src="../../../_static/vendor/fontawesome/6.1.2/js/all.min.js?digest=c5ced968eda925caa686"></script>

    <script data-url_root="../../../" id="documentation_options" src="../../../_static/documentation_options.js"></script>
    <script src="../../../_static/jquery.js"></script>
    <script src="../../../_static/underscore.js"></script>
    <script src="../../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../../_static/doctools.js"></script>
    <script src="../../../_static/clipboard.min.js"></script>
    <script src="../../../_static/copybutton.js"></script>
    <script src="../../../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../../_static/togglebutton.js"></script>
    <script src="../../../_static/js/notebook.js"></script>
    <script src="../../../_static/js/notebook.js"></script>
    <script src="../../../_static/js/notebook.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../../_static/sphinx-thebe.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'markdowns/sistemas_supervisados/clasificacion/descenso_gradiente';</script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
    <link rel="next" title="Búsqueda de hiperparámetros" href="../grid_search.html" />
    <link rel="prev" title="Regresión logística" href="regresion_logistica.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>

  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../../../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../../_static/logo.png" class="logo__image only-light" alt="Programación de inteligencia artificial - Home"/>
    <script>document.write(`<img src="../../../_static/logo.png" class="logo__image only-dark" alt="Programación de inteligencia artificial - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">INTELIGENCIA ARTIFICIAL</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../introduccion.html">Introducción</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">SISTEMAS DE APRENDIZAJE SUPERVISADO</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../introduccion.html">Introducción</a></li>
<li class="toctree-l1"><a class="reference internal" href="../proyecto_supervisado.html">Proyecto de aprendizaje supervisado</a></li>
<li class="toctree-l1"><a class="reference internal" href="../analisis_datos.html">Análisis exploratorio de datos</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../regresion/regresion.html">Problemas de regresión</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../regresion/entrenar_modelo.html">Entrenamiento del modelo</a></li>
<li class="toctree-l2"><a class="reference internal" href="../regresion/modelos/arboles_decision.html">Árboles de decisión</a></li>
<li class="toctree-l2"><a class="reference internal" href="../regresion/modelos/svm.html">Máquinas de vectores de soporte (SVM)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../regresion/modelos/regresion_ridge_lasso.html">Otros tipos de regresión</a></li>
<li class="toctree-l2"><a class="reference internal" href="../regresion/modelos/random_forest.html">Random forest</a></li>
<li class="toctree-l2"><a class="reference internal" href="../regresion/modelos/ensamble_modelos.html">Ensamble de modelos</a></li>
<li class="toctree-l2"><a class="reference internal" href="../regresion/estandarizar_y_normalizar.html">Estandarizar y normalizar</a></li>
<li class="toctree-l2"><a class="reference internal" href="../regresion/validar_modelo.html">Validar un modelo</a></li>
</ul>
</li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="introduccion.html">Problemas de clasificación</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="entrenar_clasificador_binario.html">Entrenando un clasificador binario</a></li>
<li class="toctree-l2"><a class="reference internal" href="matriz_confusion.html">Matriz de confusión</a></li>
<li class="toctree-l2"><a class="reference internal" href="curva_roc.html">Curva ROC</a></li>
<li class="toctree-l2"><a class="reference internal" href="entrenar_clasificador_multiclase.html">Clasificador multiclase</a></li>
<li class="toctree-l2 current active has-children"><a class="reference internal" href="modelos.html">Modelos de clasificación</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l3"><a class="reference internal" href="regresion_logistica.html">Regresión logística</a></li>
<li class="toctree-l3 current active"><a class="current reference internal" href="#">Descenso de Gradiente</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../grid_search.html">Búsqueda de hiperparámetros</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">ANEXOS</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../anexos/metricas/metricas_regresion.html">Anexo: Métricas de regresión</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../anexos/metricas/mse.html">Error Cuadrático Medio (MSE)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../anexos/metricas/rmse.html">Raíz del Error Cuadrático Medio (RMSE)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../anexos/metricas/mae.html">Error Absoluto Medio (MAE)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../anexos/metricas/r2.html">Coeficiente de Determinación (<span class="math notranslate nohighlight">\(R^2\)</span>)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../anexos/metricas/mape.html">Error Porcentual Absoluto Medio (MAPE)</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../bibliografia.html">Bibliografía</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">



<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Descenso de Gradiente</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#descenso-de-gradiente-estocastico">Descenso de Gradiente Estocástico</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#hiperparametros">Hiperparámetros</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#loss">loss</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#learning-rate">learning_rate</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#n-iter-no-change">n_iter_no_change</a></li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="descenso-de-gradiente">
<h1>Descenso de Gradiente<a class="headerlink" href="#descenso-de-gradiente" title="Permalink to this heading">#</a></h1>
<p>El Descenso de Gradiente Estocástico (SGD) es un algoritmo de optimización utilizado en aprendizaje automático para ajustar los parámetros de un modelo de manera eficiente.</p>
<p>Para entender como funciona, lo primero que debemos hacer es entender como funciona el descenso del gradiente. El Descenso de Gradiente es un algoritmo de optimización utilizado para minimizar la <strong>función de pérdida de un modelo</strong>. La función de pérdida mide la discrepancia entre las predicciones del modelo y los valores reales del conjunto de datos.</p>
<p>Imagina que estás en lo alto de una gran colina y tu meta es llegar al punto más bajo, que sería como encontrar el lugar ideal en términos de eficiencia o éxito. Puedes pensar en esta colina como la superficie de una función, donde la altura en cada punto refleja el nivel de “pérdida” o “error” en la tarea que estás realizando. En este escenario, tu objetivo es descender por la colina para minimizar esa pérdida y llegar al punto más bajo, que simboliza el mejor rendimiento posible.</p>
<a class="bg-primary reference internal image-reference" href="../../../_images/11.png"><img alt="../../../_images/11.png" class="bg-primary align-center" src="../../../_images/11.png" style="width: 65%;" /></a>
</br>
<p>En la práctica, se inicia el proceso con una inicialización aleatoria. Luego, de manera iterativa, se mejora gradualmente ajustando esos parámetros en pequeños pasos. En cada paso, el objetivo es reducir la función de coste, como el Error Cuadrático Medio (MSE), con el fin de llevar al algoritmo hacia la convergencia.</p>
<p>Uno de los parámetros más importantes en el descenso del gradiente es el número de pasos, ya que si introducimos un número de pasos muy elevados, se tendrán que hacer muchas iteraciones.</p>
<a class="bg-primary reference internal image-reference" href="../../../_images/12.png"><img alt="../../../_images/12.png" class="bg-primary align-center" src="../../../_images/12.png" style="width: 65%;" /></a>
</br>
<p>Por otro lado, si el número de pasos es muy bajo, pueden ocasionarse situaciones extrañas e incluso realizarse un salto de lado en la curva.</p>
<a class="bg-primary reference internal image-reference" href="../../../_images/13.png"><img alt="../../../_images/13.png" class="bg-primary align-center" src="../../../_images/13.png" style="width: 65%;" /></a>
</br>
<p>Otro problema a tener en cuenta es el del mínimo local. Es una situación en la optimización donde un algoritmo puede quedar atrapado en un punto que es un mínimo relativo pero no el mínimo global de una función. En otras palabras, es como estar en la parte más baja de una colina en lugar de estar en la base de la montaña.</p>
<p>Imagina que estás tratando de encontrar la parte más baja de una cadena montañosa en la oscuridad. Puedes terminar en una depresión local (un mínimo local), pensando que has alcanzado el punto más bajo, pero en realidad, hay un valle más profundo (el mínimo global) que no has explorado.</p>
<a class="bg-primary reference internal image-reference" href="../../../_images/14.png"><img alt="../../../_images/14.png" class="bg-primary align-center" src="../../../_images/14.png" style="width: 65%;" /></a>
</br>
<p>Este problema puede surgir cuando la función que están tratando de minimizar tiene múltiples puntos bajos, y el algoritmo elige uno cercano en lugar del punto más bajo en general. Es un desafío común en la optimización y puede afectar la eficacia de los algoritmos en la búsqueda de soluciones óptimas.</p>
<section id="descenso-de-gradiente-estocastico">
<h2>Descenso de Gradiente Estocástico<a class="headerlink" href="#descenso-de-gradiente-estocastico" title="Permalink to this heading">#</a></h2>
<p>El Descenso de Gradiente Estocástico es una variante del Descenso de Gradiente que utiliza una muestra aleatoria de datos en cada iteración. Esto lo hace particularmente eficiente cuando se trabaja con grandes conjuntos de datos.</p>
<p>En lugar de calcular el gradiente usando todo el conjunto de datos, elegimos una muestra aleatoria en cada iteración. Esto introduce un elemento estocástico y acelera el proceso de aprendizaje.</p>
<p>Posteriormente, ajustamos los parámetros utilizando la muestra seleccionada, de manera similar al Descenso de Gradiente convencional.</p>
<p>Estos pasos se deben repetir a lo largo de varias iteraciones hasta que los parámetros convergen.</p>
<p>En scikit-learn podemos utilizar la clase <code class="docutils literal notranslate"><span class="pre">SGDClassifier</span></code>. Este clasificador es particularmente útil para problemas de clasificación binaria y multiclase en conjuntos de datos grandes.</p>
<section id="hiperparametros">
<h3>Hiperparámetros<a class="headerlink" href="#hiperparametros" title="Permalink to this heading">#</a></h3>
<p>A continuación se muestran algunos de los hiperparámetros que podemos utilizar en el descenso del gradiente estocástico:</p>
<table class="table table-bordered my-table-border">
  <thead>
    <tr class="my-table-header">
      <th class="text-center my-table-header" colspan="4">HIPERPARÁMETROS DE UN SGDCLASSIFIER</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th class="left-header" scope="row">loss</th>
      <td  colspan="3">Especifica la función de pérdida a ser optimizada. Puede ser "hinge" para SVM lineal, "log" para regresión logística, "modified_huber" para clasificación binaria, entre otras opciones.</td>
    </tr>
     <tr>
      <th class="left-header" scope="row">penalty</th>
      <td  colspan="3">Especifica la norma utilizada en la penalización. Puede ser "l2" para la norma L2 (ridge), "l1" para la norma L1 (lasso), o "elasticnet" para una combinación de ambas.</td>
    </tr>
    <tr>
      <th class="left-header" scope="row">alpha</th>
      <td  colspan="3">Parámetro de regularización que controla la fuerza de la penalización. Valores más altos aumentan la regularización.</td>
    </tr>
    <th class="left-header" scope="row">learning_rate</th>
      <td  colspan="3">Controla la tasa de aprendizaje utilizada en las actualizaciones de peso.</td>
    </tr>
    <th class="left-header" scope="row">eta0</th>
      <td  colspan="3">Tasa de aprendizaje inicial para la opción "constant". No utilizado para otros esquemas de aprendizaje.</td>
    </tr>
      <th class="left-header" scope="row">max_iter</th>
      <td  colspan="3">Número máximo de iteraciones (pases sobre los datos) durante el entrenamiento.</td>
    </tr>
    </tr>
      <th class="left-header" scope="row">shuffle</th>
      <td  colspan="3">Indica si se deben barajar los datos en cada época.</td>
    </tr>
    </tr>
      <th class="left-header" scope="row">n_iter_no_change</th>
      <td  colspan="3">Número de épocas sin mejora después de las cuales se detendrá el entrenamiento.</td>
    </tr>
    </tr>
      <th class="left-header" scope="row">random_state</th>
      <td  colspan="3">Semilla utilizada para reproducir resultados aleatorios.</td>
    </tr>
  </tbody>
</table>
<p>Vamos a ver como afectan algunos de estos parámetros al entrenamiento del modelo.</p>
</section>
<section id="loss">
<h3>loss<a class="headerlink" href="#loss" title="Permalink to this heading">#</a></h3>
<p>El parámetro loss en el SGDClassifier de scikit-learn especifica la función de pérdida que se utilizará durante el entrenamiento para guiar la optimización de los pesos del modelo. La elección de la función de pérdida afecta directamente la naturaleza del aprendizaje del modelo y puede ser crucial para el rendimiento en diferentes tipos de problemas:</p>
<ul class="simple">
<li><p><strong>hinge</strong>: Utilizado comúnmente en SVM lineales para problemas de clasificación binaria y multiclase.</p></li>
<li><p><strong>log_loss</strong>: Aplicable a problemas de clasificación binaria y multiclase.</p></li>
<li><p><strong>modified_huber</strong>: Principalmente en problemas de clasificación binaria.</p></li>
</ul>
<p>En general, “hinge” y “log_loss” son opciones sólidas para problemas de clasificación, pero puede ser útil experimentar con varias funciones de pérdida para encontrar la más adecuada para tu conjunto de datos específico.</p>
</section>
<section id="learning-rate">
<h3>learning_rate<a class="headerlink" href="#learning-rate" title="Permalink to this heading">#</a></h3>
<p>El parámetro learning_rate en el SGDClassifier de scikit-learn controla la tasa de aprendizaje durante el entrenamiento. La tasa de aprendizaje es un hiperparámetro crucial que afecta la magnitud de los ajustes de los pesos del modelo en cada iteración del Descenso de Gradiente Estocástico (SGD). Aquí hay algunas opciones comunes para el parámetro learning_rate y sus características:</p>
<ul class="simple">
<li><p><strong>optional</strong>: Es una buena elección predeterminada y funciona bien en muchos casos. Puede adaptarse a cambios en la geometría de la función de pérdida durante el entrenamiento.</p></li>
<li><p><strong>constant</strong>: Útil cuando la geometría de la función de pérdida no cambia significativamente durante el entrenamiento. Puede requerir ajuste manual de la tasa de aprendizaje.</p></li>
<li><p><strong>invscaling</strong>: Puede ser beneficioso para converger hacia el mínimo de manera más suave a medida que avanza el entrenamiento.</p></li>
<li><p><strong>adaptive</strong>: Puede ser útil cuando las características tienen escalas diferentes y se desea una adaptación más precisa.</p></li>
</ul>
</section>
<section id="n-iter-no-change">
<h3>n_iter_no_change<a class="headerlink" href="#n-iter-no-change" title="Permalink to this heading">#</a></h3>
<p>El parámetro n_iter_no_change en el SGDClassifier de scikit-learn es un hiperparámetro que especifica el número de épocas (iteraciones) durante las cuales se permite que la función de pérdida en el conjunto de validación no mejore antes de detener el entrenamiento.</p>
<p>Un valor bajo de n_iter_no_change puede ser útil para evitar entrenamientos prolongados. Si el rendimiento del modelo en el conjunto de validación no mejora significativamente después de un número limitado de épocas, detener el entrenamiento puede ahorrar tiempo computacional.</p>
<p>En algunos casos, un modelo puede continuar ajustándose demasiado a los datos de entrenamiento y empeorar en datos nuevos (sobreajuste). Limitar el número de épocas sin mejoras puede ayudar a detener el entrenamiento antes de que el modelo se sobreajuste.</p>
<p>n_iter_no_change puede ser crucial para la eficiencia del entrenamiento. En problemas donde el modelo converge rápidamente y no hay ganancias significativas después de cierto punto, detener el entrenamiento puede ser beneficioso.</p>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./markdowns/sistemas_supervisados/clasificacion"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  <!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="regresion_logistica.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Regresión logística</p>
      </div>
    </a>
    <a class="right-next"
       href="../grid_search.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Búsqueda de hiperparámetros</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#descenso-de-gradiente-estocastico">Descenso de Gradiente Estocástico</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#hiperparametros">Hiperparámetros</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#loss">loss</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#learning-rate">learning_rate</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#n-iter-no-change">n_iter_no_change</a></li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Manuel Sánchez Gomis
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../_static/scripts/bootstrap.js?digest=c5ced968eda925caa686"></script>
<script src="../../../_static/scripts/pydata-sphinx-theme.js?digest=c5ced968eda925caa686"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>